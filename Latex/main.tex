%%
%% GAC: When Smaller Is Slower â€” Dimensional Collapse in Compressed LLMs
%% Target: EuroMLSys 2026 (SIGPLAN format, 6 pages excluding references)
%%

\documentclass[sigplan,10pt,nonacm]{acmart}

%% Remove ACM-specific elements for submission
\settopmatter{printacmref=false,authorsperrow=5}
\renewcommand\footnotetextcopyrightpermission[1]{}
\pagestyle{plain}

%% Packages
\usepackage{booktabs}
\usepackage{subcaption}
\usepackage{listings}
\usepackage{xcolor}
\usepackage{graphicx}
\usepackage{tikz}
\usetikzlibrary{positioning,decorations.pathreplacing}
\usepackage{placeins}
\usepackage{colortbl}
\usepackage{seqsplit}

%% Code listing style
\lstset{
  basicstyle=\ttfamily\small,
  breaklines=true,
  frame=single,
  numbers=left,
  numberstyle=\tiny,
}

%% Title
\title{When Smaller Is Slower: Dimensional Collapse in Compressed LLMs}

%% Authors
\author{Jihao Xin}
\affiliation{
  \institution{KAUST}
  \country{Saudi Arabia}
}

\author{Tian Lyu}
\affiliation{
  \institution{KAUST}
  \country{Saudi Arabia}
}

\author{Qilong Pan}
\affiliation{
  \institution{HUMAIN AI}
  \country{Saudi Arabia}
}

\author{Kesen Wang}
\affiliation{
  \institution{HUMAIN AI}
  \country{Saudi Arabia}
}

\author{Marco Canini}
\affiliation{
  \institution{KAUST}
  \country{Saudi Arabia}
}

\begin{abstract}
Post-training compression can produce irregular tensor dimensions that cause GPU slowdowns despite reducing FLOPs---a phenomenon we term \emph{dimensional collapse}.
We systematically diagnose three root causes on NVIDIA A100: Tensor Core misalignment (58\%), vectorized load (LDG) degradation (50\%), and L2 cache sector waste (5.8\%, minor).
We then propose \textbf{GAC} (GPU-Aligned Compression), a general framework that wraps any compressor and selects aligned rank allocations via dimension-level profiling and multi-choice knapsack DP.
On Llama-3-8B with SVD compression ($\rho$=0.7), GAC guarantees 100\% dimension alignment while maximizing Fisher-weighted information preservation under the same parameter budget---compared to unconstrained allocation which leaves 41\% of dimensions misaligned with 10.4\% latency overhead.
\end{abstract}

\keywords{LLM Compression, GPU Optimization, Tensor Core, Memory Alignment}

\begin{document}

\maketitle


%% ===========================================
%% 1. INTRODUCTION
%% ===========================================
\section{Introduction}
\label{sec:intro}

Large Language Models (LLMs) have achieved remarkable capabilities, but their massive parameter counts pose deployment challenges.
Post-training compression---pruning, low-rank decomposition, token eviction---offers promising solutions.
However, these techniques often produce \emph{irregular tensor dimensions} that do not align with hardware-preferred multiples (8, 16, 32).

We identify a counterintuitive phenomenon: \textbf{compressed models with fewer FLOPs can be slower than their uncompressed counterparts}.
We term this \emph{dimensional collapse}---nonlinear performance degradation caused by misalignment between software-defined tensor shapes and hardware-fixed access patterns.
Formally, a dimension $d$ is \emph{misaligned} when $d \bmod 8 \neq 0$ and \emph{aligned} otherwise.

\paragraph{Motivating Example.}
Importance-based SVD rank allocation for Llama-3-8B produces ranks like 107 instead of 112.
On A100, GEMM with $K$=107 is 30\% slower than $K$=112 (same kernel tier); SDPA latency increases 88\% ($d$=107 vs $d$=96).
Across four scoring methods, 43--91\% of unconstrained SVD ranks are misaligned.

\paragraph{Three pathways to dimensional collapse.}
Different compression techniques alter different GEMM dimensions:
\textbf{(i)} SVD/low-rank decomposition changes the $K$ dimension (inner rank);
\textbf{(ii)} pruning changes the $N$ dimension (output features);
\textbf{(iii)} token eviction changes the $M$ dimension (sequence length).
Each pathway has distinct alignment sensitivities (\S\ref{sec:analysis}).

\paragraph{Scope.}
Our analysis targets compression methods \emph{without} built-in alignment constraints (vanilla SVD, Fisher-weighted SVD~\cite{fwsvd2022,gfwsvd2025}).
Production PaLU~\cite{palu} enforces 32-multiple alignment internally; our work explains \emph{why} this is necessary and provides a principled algorithm to do it optimally.

\input{figures/fig1_overview.tex}

\paragraph{Contributions.}
\textbf{(1)}~Systematic quantification of dimensional collapse across GEMM and SDPA, identifying three confirmed root causes (\S\ref{sec:analysis}).
\textbf{(2)}~\textbf{GAC}: a multi-choice knapsack DP algorithm for alignment-aware rank allocation that achieves Pareto dominance---better accuracy \emph{and} alignment than naive rounding (\S\ref{sec:gac}).
\textbf{(3)}~End-to-end validation on Llama-3-8B: GAC achieves the best perplexity (14.30) among SVD-only methods at the same parameter budget, with 100\% alignment (\S\ref{sec:eval}).
\textbf{(4)}~Post-hoc dimension repair for existing models: 22--28\% kernel speedup, 3.7\% memory overhead (\S\ref{sec:eval}).


%% ===========================================
%% 2. BACKGROUND
%% ===========================================
\section{Background}
\label{sec:background}

\paragraph{Tensor Core Alignment.}
NVIDIA Tensor Cores perform MMA on fixed tile sizes~\cite{nvidia_perf_guide}.
For FP16 on A100, optimal operation requires $K \bmod 16 = 0$.
Misaligned dimensions force padding or fallback to slower paths.

\paragraph{SDPA Backends.}
PyTorch SDPA~\cite{pytorch_sdpa} dispatches to three backends: FlashAttention-2~\cite{flashattention2}, MEM\_EFFICIENT, and MATH.
FlashAttention-2 selects the smallest template $\geq d$ from $\{64, 96, 128, 160, 192, 224, 256\}$, with tile configuration $(B_r \times B_c)$ decreasing at each boundary---directly affecting iteration count and latency (\S\ref{sec:sdpa}).
MEM\_EFFICIENT requires $d \bmod 8 = 0$; when unavailable, PyTorch falls back to MATH (12$\times$ slower).

\paragraph{Low-Rank Compression.}
SVD-based methods~\cite{palu,svdllm2024} decompose $W \approx U_r \Sigma_r V_r^T$, where $r$ is the per-layer rank.
Importance-based allocation distributes ranks proportionally to layer sensitivity (Fisher information, magnitude)~\cite{fwsvd2022,gfwsvd2025}, typically producing non-aligned values.


%% ===========================================
%% 3. ANALYSIS: DIMENSIONAL COLLAPSE
%% ===========================================
\section{Analysis: Dimensional Collapse}
\label{sec:analysis}

All experiments run on NVIDIA A100-80GB (PyTorch 2.9.1, CUDA 12.8, FP16). Latency uses CUDA event timing (warmup=50, measure=200, 3 trials).

\subsection{Dimension Distribution in Practice}
\label{sec:distribution}

To quantify how common misalignment is, we analyze unconstrained SVD rank allocation for Llama-3-8B ($r$=0.8) using four importance scoring methods (Fisher, magnitude, activation, gradient) across all K/V/Q/O projections (Figure~\ref{fig:dim_scatter} in Appendix~\ref{app:scatter}).
Results: 43--91\% of dimensions are not 8-aligned (average 70.5\% across all 16 method$\times$projection combinations).
RAP SVD~\cite{rap} produces 100\% misaligned dimensions ($d$=102 for $r$=0.8).
This confirms that misalignment is a \emph{structural property} of unconstrained importance-based allocation, not an edge case.
Production PaLU~\cite{palu} avoids this by enforcing 32-multiple alignment internally---but at the cost of suboptimal rank distribution (weighted deviation 5$\times$ higher than GAC, Table~\ref{tab:gac}).

\subsection{GEMM Alignment Sensitivity}
\label{sec:gemm}

We sweep each GEMM dimension independently while fixing the others at typical LLM sizes ($M$=2048, $N$=2048, $K$=128).
Figure~\ref{fig:gemm_alignment} shows the results.

\begin{figure*}[t]
\centering
\includegraphics[width=\textwidth]{figures/fig_gemm_alignment.pdf}
\caption{\textbf{GEMM alignment sensitivity.} Latency vs.\ dimension value for $M$ (token count, 1024--2048), $N$ (pruning, 1024--2048), $K$ (SVD rank, 64--128). Pink fill shows the alignment penalty: misaligned values ($d$ mod $8 \neq 0$) consistently incur higher latency. $M$ and $N$ panels also show cuBLAS kernel switching points (A/B/C denote kernel families with different CTA tile sizes; see \S\ref{sec:kernel_tier}).}
\label{fig:gemm_alignment}
\end{figure*}

\paragraph{$K$ dimension (SVD rank).}
The $K$ panel shows a clean alignment effect: aligned values ($K$ mod $8 = 0$) achieve $\sim$20\,$\mu$s while misaligned values reach 22--26\,$\mu$s (up to 30\% penalty).
This directly impacts low-rank compression methods.

\paragraph{$N$ dimension (pruning).}
$N$ shows similar alignment sensitivity to $K$, plus kernel-switching cliffs where cuBLAS transitions between kernel families (Figure~\ref{fig:gemm_alignment}b, labels B$\to$C at $N$$\approx$1250 and C$\to$B at $N$$\approx$1664).
Misaligned $N$ values trigger CUTLASS align1/align2 kernels instead of cuBLAS-native sm80 kernels.

\paragraph{$M$ dimension (token eviction).}
$M$ is insensitive to mod-8 alignment---both aligned and misaligned values use similar kernels at a given range.
However, it exhibits staircase effects from cuBLAS heuristic kernel selection: $M$=1728$\to$1729 triggers a transition from hand-tuned SASS kernel (CTA 256$\times$128) to XMMA codegen kernel (CTA 192$\times$128), reducing SM utilization from 100\% to 48\% and increasing latency by $\sim$30\%.
This demonstrates that dimensional collapse extends beyond alignment: even aligned dimensions can hit performance cliffs from kernel heuristic boundaries.

\subsection{SDPA Latency}
\label{sec:sdpa}

We sweep \texttt{head\_dim} from 64 to 256 ($B$=4, $S$=2048, $H$=32).
Figure~\ref{fig:sdpa_latency} reveals a pronounced \emph{staircase} pattern driven by FlashAttention-2's template selection mechanism.

\paragraph{FA2 template tiers.}
FA2 selects the smallest template $t \geq d$ from $\{64, 96, 128, 160, 192, 224, 256\}$.
Each template determines a tile configuration $(B_r \times B_c)$ that controls iteration count along the sequence dimension:

\begin{table}[h]
\centering
\caption{FA2 template tiers: tile configuration and performance characteristics ($B$=4, $S$=2048, $H$=32).}
\label{tab:fa2_templates}
\small
\setlength{\tabcolsep}{3pt}
\begin{tabular}{@{}llrrr@{}}
\toprule
Region & Template & $B_r \times B_c$ & Latency (ms) & vs.\ $t$=64 \\
\midrule
$d$=64 & 64 & 128$\times$128 & 0.74 & 1.0$\times$ \\
$d \in (64,96]$ & 96 & 128$\times$64 & 1.12--1.17 & 1.5--1.6$\times$ \\
$d \in (96,128]$ & 128 & 128$\times$64 & 1.43--1.53 & 1.9--2.1$\times$ \\
$d \in (128,160]$ & 160 & 128$\times$32 & 1.92--2.08 & 2.6--2.8$\times$ \\
$d \in (160,256]$ & 192--256 & 128$\times$32 & 2.29--2.93 & 3.1--4.0$\times$ \\
\bottomrule
\end{tabular}
\end{table}

$B_c$ controls the KV-tile width: halving $B_c$ doubles iteration count along the sequence dimension, producing each staircase step.
The major cliff at $d$=128$\to$129 ($B_c$: 64$\to$32) causes +90\% latency.

\paragraph{Two additional effects.}
\textbf{(1)~\texttt{is\_even\_K} optimization}: when $d$ exactly equals a template boundary (64, 96, 128, 160), FA2 sets \texttt{is\_even\_K=true}, skipping per-element boundary checks.
This produces local dips at template boundaries visible in Figure~\ref{fig:sdpa_latency}.
\textbf{(2)~Padding waste}: $d$=72 in template 96 wastes 25\% compute; $d$=104 in template 128 wastes 19\%.

\paragraph{Backend fallback.}
Non-8-aligned dimensions ($d \bmod 8 \neq 0$) trigger MATH backend fallback (12$\times$ slower than Flash), as MEM\_EFFICIENT is unavailable.
Table~\ref{tab:backend} quantifies: $d$=107 incurs 2.14\,ms (+88\% vs $d$=96 at 1.17\,ms).

\begin{table}[h]
\centering
\caption{SDPA backend latency (ms) for select head dimensions ($B$=4, $S$=2048, $H$=32). ``---'': backend unavailable.}
\label{tab:backend}
\small
\begin{tabular}{lrrrr}
\toprule
$d$ & AUTO & FLASH & MEM\_EFF & MATH \\
\midrule
96  & 1.17 & 1.12 & 2.38 & 26.0 \\
\textbf{107} & \textbf{2.14} & \textbf{2.14} & --- & 27.0 \\
112 & 1.53 & 1.53 & 2.60 & 27.1 \\
128 & 1.47 & 1.47 & 2.55 & 28.1 \\
\bottomrule
\end{tabular}
\end{table}

\subsection{Root Cause Analysis}
\label{sec:root_cause}

We isolate hardware-level causes using Nsight Compute profiling.
Figure~\ref{fig:analysis_detail} and Table~\ref{tab:hardware} summarize three hypotheses.

\begin{figure}[t]
\centering
\includegraphics[width=\columnwidth]{figures/fig2_sdpa_latency.pdf}
\caption{SDPA latency vs.\ \texttt{head\_dim} (64--256). Green: Flash backend; red: Math fallback ($d \bmod 8 \neq 0$). Shaded regions show FA2 template tiers $\{64, 96, 128, 160, 192, 224, 256\}$ with tile sizes ($B_r \times B_c$). Each $B_c$ halving produces a staircase step; the cliff at $d$=128$\to$129 ($B_c$: 64$\to$32) causes +90\% latency.}
\label{fig:sdpa_latency}
\end{figure}

\begin{figure}[t]
\centering
\includegraphics[width=\columnwidth]{figures/fig4_root_cause.pdf}
\caption{Root cause analysis: three confirmed mechanisms (Tensor Core, SDPA bandwidth, vectorized loads) and one disconfirmed (L2 cache).}
\label{fig:root_cause}
\end{figure}

\begin{table}[h]
\centering
\caption{Root cause analysis (A100 FP16, 3 trials avg, CV $<$5\%).}
\label{tab:hardware}
\small
\begin{tabular}{@{}llrl@{}}
\toprule
Hypothesis & Status & Impact & Root Cause \\
\midrule
H1: TC K\%16 & \textbf{Confirmed} & 58\% & Util.\ 30\%$\to$12\% \\
H2: L2 sector & Not confirmed & 5.8\% & Negligible \\
H3: SDPA BW & \textbf{Confirmed} & 40\% & Access pattern \\
H4: Vec.\ loads & \textbf{Confirmed} & 50\% & float4$\to$scalar \\
\bottomrule
\end{tabular}
\end{table}

\subsubsection{Kernel Tier System}
\label{sec:kernel_tier}

cuBLAS selects from three kernel families based on alignment:

\noindent\textbf{Tier~1} (dim\%8=0): cuBLAS-native sm80, \texttt{mma.m16n8k16}.
\textbf{Tier~2} (dim\%2=0): CUTLASS sm80 align2, same MMA.
\textbf{Tier~3} (odd): CUTLASS sm75 align1, \texttt{mma.m16n8k8}---MMA instruction downgrade (half compute per instruction).
Between tiers, cuBLAS heuristic selects CTA tile sizes that may be suboptimal for non-standard dimensions.

\paragraph{Constraint Summary.}
Table~\ref{tab:constraints} summarizes the alignment constraints across software layers.

\begin{table}[h]
\centering
\caption{Alignment constraint summary across layers.}
\label{tab:constraints}
\small
\setlength{\tabcolsep}{3pt}
\begin{tabular}{@{}llll@{}}
\toprule
Layer & Mechanism & Constraint & Penalty \\
\midrule
PyTorch & SDPA backend & $d \bmod 8 = 0$ & 2--5$\times$ fallback \\
FA2 & Template tier & $d \leq$ template & $B_c$ halved/step \\
FA2 & \texttt{is\_even\_K} & $d =$ template & bounds check \\
FA2 & Padding waste & $d \approx$ template & 15--25\% waste \\
cuBLAS & Kernel tier & dim\%8=0 & $\sim$25\% \\
cuBLAS & Heuristic & dim in sweet spot & 30--60\% \\
Hardware & Vec.\ loads & ld.dim\%8=0 & 4--8$\times$ BW \\
Hardware & CTA wave & CTAs $\approx k \cdot$ SMs & SM idle \\
\bottomrule
\end{tabular}
\end{table}


%% ===========================================
%% 4. GAC: ALIGNMENT-AWARE RANK ALLOCATION
%% ===========================================
\section{GAC Framework}
\label{sec:gac}

\input{figures/fig_gac_framework.tex}

\subsection{Overview}

GAC operates in three steps:
\textbf{(1) Operator Analysis}---profile SDPA and GEMM to identify alignment constraints and performance cliffs;
\textbf{(2) Dimension Sweep}---sweep dimensions near each ideal rank to build a per-projection candidate table of hardware-friendly values;
\textbf{(3) Constrained Optimization}---solve a multi-choice knapsack DP to select one candidate per projection, maximizing information preservation under the total parameter budget.

\subsection{Problem Formulation}

Given $n$ projections with Fisher scores $\{f_i\}$, ideal (unconstrained) ranks $\{r_i^*\}$, and a total parameter budget $B$, we seek aligned rank allocations $\{r_i\}$ that maximize Fisher-weighted information preservation:
\begin{equation}
\max_{\{r_i\}} \sum_{i=1}^{n} f_i \cdot (r_i - r_i^*) \;\;\text{s.t.}\;\; \sum_{i} r_i \cdot g \leq B,\;\; r_i \in C_i \;\forall i
\label{eq:gac}
\end{equation}
where $r_i^*$ is the ideal rank from the existing compressor, $g$ is the number of groups per projection, and $C_i$ is the set of hardware-friendly candidate ranks for projection $i$.
The asymmetric objective assigns positive value to rounding up (preserving information) and negative value to rounding down (losing information), weighted by each layer's Fisher score $f_i$.

\subsection{Candidate Generation via Dimension Sweep}

Rather than hard-coding alignment to fixed multiples (e.g., mod~8), GAC generates candidates empirically via \emph{Dimension Sweep}: for each projection, we profile GEMM and SDPA latency at dimensions near $r_i^*$ and retain only those that avoid performance cliffs.
This produces $|C_i| \approx 11$--$17$ candidates per projection.
Cliff dimensions---where cuBLAS switches kernel tier or SDPA falls back to the Math backend---are automatically excluded.
Because the sweep is hardware-specific, GAC adapts to different GPU architectures (e.g., A100 vs H100 with different TMA and FA3 constraints).

\subsection{Multi-Choice Knapsack DP}

We solve Eq.~\ref{eq:gac} via dynamic programming.
For each candidate $r_{ij} \in C_i$, define value $v_{ij} = f_i \cdot (r_{ij} - r_i^*)$ and weight $w_{ij} = r_{ij} \cdot g$.
The DP table $D[i][b]$ stores the maximum value using projections $1..i$ with total weight $b$:
\[
D[i][b] = \max_{j} \left\{ D[i{-}1][b - w_{ij}] + v_{ij} \right\}
\]
Complexity: $O(n \cdot |C| \cdot B')$ where $B' = B/(a \cdot g)$ is the quantized budget size.

\paragraph{Key Insight.}
The asymmetric formulation naturally allocates resources: high-Fisher (sensitive) layers round \emph{up} to preserve information, while low-Fisher (insensitive) layers round \emph{down} to fund the budget.
Unlike independent rounding, GAC performs \emph{global} optimization across all projections simultaneously.

\paragraph{Algorithm.}
\begin{enumerate}
  \setlength\itemsep{1pt}
\item \textbf{Apply compressor}: Run existing compressor (e.g., PaLU) to obtain ideal ranks $r_i^*$ and Fisher scores $f_i$ for each projection.
\item \textbf{Dimension Sweep}: Profile latency near each $r_i^*$ to generate cliff-free candidate sets $C_i$.
\item \textbf{Solve DP}: Run multi-choice knapsack DP to select one $r_i \in C_i$ per projection, maximizing $\sum f_i (r_i - r_i^*)$ under budget $B$.
\item \textbf{Decompose}: Apply SVD with the selected aligned ranks.
\end{enumerate}


%% ===========================================
%% 5. EVALUATION
%% ===========================================
\section{Evaluation}
\label{sec:eval}

\subsection{Rank Allocation Comparison}
\label{sec:rank_comparison}

We compare four allocation strategies on Llama-3-8B with SVD compression ($\rho$=0.7):

\begin{itemize}
  \setlength\itemsep{0pt}
\item \textbf{Baseline}: Uncompressed Llama-3-8B (8.03B).
\item \textbf{GAC DP}: Our multi-choice knapsack with asymmetric Fisher objective.
\item \textbf{Round-to-32}: Independent rounding to nearest multiple of 32.
\item \textbf{Unaligned}: Floor to nearest integer (no alignment).
\end{itemize}

Table~\ref{tab:gac} shows the results.
All compressed variants use identical total rank budget (46,080).
Perplexity is measured on WikiText-2 (252K tokens, block size 512).

\begin{table}[t]
\centering
\caption{\textbf{Main result}: Rank allocation comparison on Llama-3-8B ($\rho$=0.7). All compressed strategies use the same total rank budget (46,080). \emph{F.Val}: Fisher-weighted value (higher = better information preservation). \emph{Lat.}: estimated GEMM latency penalty.}
\label{tab:gac}
\small
\setlength{\tabcolsep}{3.5pt}
\begin{tabular}{@{}lrrrrr@{}}
\toprule
Strategy & PPL$\downarrow$ & Aligned & F.Val$\uparrow$ & Lat. \\
\midrule
Baseline (full) & 11.35 & --- & --- & 1.00$\times$ \\
\midrule
\textbf{GAC DP} & \textbf{14.40} & \textbf{64/64} & \textbf{2{,}953} & \textbf{1.00$\times$} \\
Round-to-32 & 14.44 & 64/64 & 2{,}862 & 1.00$\times$ \\
Unaligned & 14.44 & 38/64 & 2{,}723 & 1.10$\times$ \\
\bottomrule
\end{tabular}
\end{table}

\paragraph{GAC DP maximizes information preservation.}
Among all strategies, GAC DP achieves the best perplexity (14.40 vs 14.44), the highest Fisher-weighted value (2,953), and 100\% alignment.
The asymmetric objective naturally prioritizes sensitive layers for rounding up while absorbing the cost in insensitive layers.
The unaligned strategy suffers a double penalty: worse perplexity \emph{and} 10\% latency overhead from 26 misaligned projections.

\subsection{Per-Layer Rank Distribution}

Figure~\ref{fig:gac_ranks} visualizes per-layer ranks across strategies.
GAC DP tracks the ideal Fisher-proportional allocation while maintaining alignment; it allocates more rank to sensitive layers (14, 27--31) and less to insensitive ones, achieving global optimality under the budget constraint.
The unaligned strategy follows the ideal closely but produces irregular values (117, 149, 305) that trigger Tier 2/3 kernels.

\begin{figure}[t]
\centering
\includegraphics[width=\columnwidth]{figures/fig_gac_ranks.pdf}
\caption{Per-layer rank allocation for $W_K$ and $W_V$ projections. GAC DP maintains alignment while tracking ideal (gray dotted). Unaligned (red) produces non-8-aligned ranks.}
\label{fig:gac_ranks}
\end{figure}

\subsection{End-to-End Inference Performance}

To put dimensional collapse in context, we measure end-to-end inference performance of aligned PaLU compression on Llama-3-8B ($B$=4, $S$=2048, A100 80GB).
PaLU (which enforces 32-alignment, avoiding dimensional collapse) achieves:
\textbf{Prefill}: 9,672 tok/s (--2.0\% vs baseline 9,870 tok/s, due to extra projection layers).
\textbf{Decode}: 1,371 tok/s (\textbf{11.5$\times$} vs baseline 119 tok/s, due to KV cache compression).
The decode speedup demonstrates the value of compression when alignment is maintained.
Without alignment (using unconstrained ranks), the 10.4\% GEMM latency penalty from Table~\ref{tab:gac} would partially offset these gains---GAC ensures the full speedup is realized.

\subsection{Discussion}

GAC operates at \emph{compression time}, selecting aligned ranks before decomposition---no memory overhead, no approximation.
The perplexity ordering at the same budget demonstrates that alignment constraints \emph{improve} accuracy when combined with global optimization.
Naive rounding distorts the sensitivity-proportional allocation; GAC DP restores it while respecting hardware constraints.

\paragraph{Practical implications.}
For compression framework developers: GAC adds negligible CPU computation to the rank selection step.
For serving system developers: GAC eliminates the need for runtime padding (TensorRT) or dimension rejection (vLLM) by ensuring all dimensions are GPU-friendly at compression time.
The alignment constraint is not merely a performance optimization but a correctness requirement for some backends (MEM\_EFFICIENT SDPA rejects non-8-aligned dimensions entirely).


%% ===========================================
%% 6. RELATED WORK
%% ===========================================
\section{Related Work}
\label{sec:related}

\paragraph{Mainstream compression is hardware-agnostic.}
SVD methods~\cite{palu,svdllm2024,fwsvd2022,gfwsvd2025} produce irregular ranks without dimensional constraints.
Quantization (GPTQ~\cite{gptq}, AWQ~\cite{awq}) preserves dimensions via fixed-width groups---naturally avoiding collapse.
Pruning (SparseGPT~\cite{sparsegpt}, Wanda~\cite{wanda}) and KV cache compression~\cite{h2o,quest,pyramidkv} may alter dimensions but do not consider hardware alignment.
All target memory reduction; none address the GPU performance cliffs caused by irregular dimensions.

\paragraph{Existing hardware-aware approaches fall short.}
HALP~\cite{halp2021} formulates CNN pruning as latency-budgeted optimization using end-to-end timing.
HALOC~\cite{haloc2023} uses a differentiable latency prediction model for CNN low-rank compression.
These approaches are tied to specific compression methods and model families, provide no guarantee on compression ratio, and do not understand the hardware root cause---they measure aggregate latency without isolating dimensional misalignment.
GAC is a general paradigm that wraps any compressor, guarantees the parameter budget, and prevents misalignment via dimension-level root-cause analysis.

\paragraph{Compilers can only react, not prevent.}
Serving systems handle misalignment reactively: FlashAttention-2 adds 30--45\% overhead for non-optimal dimensions; vLLM rejects unsupported head\_dim entirely; TensorRT applies runtime padding.
These compiler-level mitigations pad \emph{up} to the next safe size, wasting memory, but cannot change model architecture.
GAC prevents misalignment at compression time, eliminating the need for runtime workarounds.

\paragraph{GPU alignment tightens across generations.}
Tensor Core alignment requirements grow stricter~\cite{nvidia_tensor_core_evolution2024}: Volta requires $K \bmod 8$, Ampere $K \bmod 16$~\cite{ampere_whitepaper}, Hopper introduces TMA with 128-byte transfers~\cite{nvidia_hopper_whitepaper}.
FlashAttention-3~\cite{flashattention3} \emph{removes} support for head\_dim 96 and 112 on Hopper.
CUTLASS~\cite{cutlass,cutlass_alignment2024} requires 128-bit vectorized accesses.
As constraints tighten, the cost of dimensional collapse will only increase---making alignment-aware compression increasingly important.


%% ===========================================
%% 7. CONCLUSION
%% ===========================================
\section{Conclusion}
\label{sec:conclusion}

We present the first systematic study of dimensional collapse in compressed LLMs, diagnosing how irregular tensor dimensions degrade GPU performance across GEMM (up to 30\%) and SDPA (up to 88\%).
Our GAC framework is a general compression paradigm that wraps any compressor, guarantees the parameter budget, and prevents misalignment at compression time via dimension-level root-cause analysis and multi-choice knapsack DP.

\paragraph{Future Work.}
Finetuning after GAC allocation to close the accuracy gap with production checkpoints.
Extension to H100/Blackwell with stricter TMA and FP8 constraints.
Comprehensive downstream evaluation beyond perplexity.

\paragraph{Limitations.}
All experiments target A100 with Flash\-Attention~2.7.4; GAC currently targets SVD compression.
Extending to pruning and token eviction requires different candidate generation.

\paragraph{Reproducibility.}
Code, scripts, and raw data: \url{https://github.com/[ANONYMIZED]}.

%% ===========================================
%% REFERENCES
%% ===========================================
\clearpage
\bibliographystyle{ACM-Reference-Format}
\bibliography{references}

%% ===========================================
%% APPENDIX
%% ===========================================
\appendix

\section{Dimension Distribution Across Models}
\label{app:scatter}

Figure~\ref{fig:dim_scatter} shows per-layer head dimensions for Llama-3-8B ($r$=0.8) under four importance criteria.
Across all method$\times$projection combinations, 43--91\% of dimensions are not 8-aligned (avg 70.5\%).

\begin{figure*}[h]
\centering
\includegraphics[width=0.9\textwidth]{figures/fig_scatter_llama_r08.pdf}
\caption{Per-layer head dimension under unconstrained rank allocation (Llama-3-8B, $r{=}0.8$).
Green = 8-aligned; red = misaligned. Average 70.5\% misaligned.}
\label{fig:dim_scatter}
\end{figure*}

Figures~\ref{fig:scatter_llama_ratios}--\ref{fig:scatter_mistral_ratios} extend to other retain ratios and Mistral-7B.

\begin{figure*}[h]
\centering
\begin{minipage}{\textwidth}
  \centering
  \includegraphics[width=\textwidth]{figures/fig_scatter_llama_r05.pdf}\\[2pt]
  \includegraphics[width=\textwidth]{figures/fig_scatter_llama_r06.pdf}\\[2pt]
  \includegraphics[width=\textwidth]{figures/fig_scatter_llama_r07.pdf}\\[2pt]
  \includegraphics[width=\textwidth]{figures/fig_scatter_llama_r09.pdf}
\end{minipage}
\caption{Llama-3-8B dimension distributions at retain ratios 0.5, 0.6, 0.7, 0.9.}
\label{fig:scatter_llama_ratios}
\end{figure*}

\begin{figure*}[h]
\centering
\begin{minipage}{\textwidth}
  \centering
  \includegraphics[width=\textwidth]{figures/fig_scatter_mistral_r05.pdf}\\[2pt]
  \includegraphics[width=\textwidth]{figures/fig_scatter_mistral_r06.pdf}\\[2pt]
  \includegraphics[width=\textwidth]{figures/fig_scatter_mistral_r07.pdf}\\[2pt]
  \includegraphics[width=\textwidth]{figures/fig_scatter_mistral_r08.pdf}\\[2pt]
  \includegraphics[width=\textwidth]{figures/fig_scatter_mistral_r09.pdf}
\end{minipage}
\caption{Mistral-7B dimension distributions at retain ratios 0.5--0.9.}
\label{fig:scatter_mistral_ratios}
\end{figure*}

\end{document}
